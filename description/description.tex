\documentclass[a4paper]{scrartcl}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage[affil-it]{authblk}
\usepackage{graphicx}

\newcommand*{\class}[1]{\textsc{#1}}
\newcommand*{\email}[1]{\texttt{#1}}

\title{TTC'16 Live Contest Case Study}
\subtitle{Execution of dataflow-based model transformations}

\author{Antonio Garcia-Dominguez}
\affil{\small Aston University, Birmingham, UK \\ \texttt{a.garcia-dominguez@aston.ac.uk}}
\date{}

\begin{document}

\maketitle

\begin{abstract}
  Abstract.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Model-to-model transformation frameworks and tools have evolved in the
recent years to process larger models more efficiently. Traditional
\emph{batch} transformation engines took the entire source model(s)
and produced the entire target model(s) exactly once. A small change
would require going again through the entire model. Alternatively, an
\emph{incremental} transformation engine processes only the change
itself, updating the target model(s) as needed.

Various approaches for incremental transformations are present in the
literature: for instance, ReactiveATL~\cite{tisi_lazy_2011} is an
alternative execution engine of ATL which only computes and updates
results on-demand as the model changes. VIATRA3 is a general purpose
framework for reactive transformations~\cite{bergmann_viatra_2015}, in
which users write rules that trigger as the model changes.
% Beyond
% model transformations, IncQuery~\cite{bergmann_incremental_2010} is an
% incremental query language that builds a RETE network and feeds EMF
% change notifications to keep query matches up to date.
Streaming transformations have been studied by Cuadrado and
Lara~\cite{cuadrado_streaming_2013} with the Eclectic tool and its
ATL-like language, and by David, Rath, and
Varr√≥~\cite{david_streaming_2014} through complex event processing.

Most of these systems can be seen as complex transformations of
rule-based systems into event-driven systems, or frameworks that allow
for writing these event-driven systems. This case suggests studying a
type of notation that may be more directly amenable to incremental
execution: a graph of model-oriented primitives which generate and
process streams of tuples. The notation is inspired on popular
Extract-Transform-Load (ETL) tools such as Pentaho Data
Integration\footnote{\url{http://community.pentaho.com/projects/data-integration/}}
or Talend Data
Integration\footnote{\url{https://www.talend.com/products/data-integration}}. As
data integration can be considered a form of model transformation,
perhaps there might be lessons to learn from these languages. In
addition to their potentially simpler incrementality, breaking rules
into smaller primitives might increase the level of detail of the
execution traces of the transformation.

This case study presents a simplistic version of such a notation, with
primitives subdivided into ``minimal'' and ``extended''
sets. Participants are tasked with writing an execution engine using
their favorite approach (e.g. code generation or model interpretation)
and tool, which may support batch and/or incremental transformations.

All the resources are included in the official Github
repository\footnote{\url{https://github.com/TransformationToolContest/ttc16-live-contest}}. These
resources are mentioned in Section~\ref{sec:case}. The evaluation
criteria for the provided solutions are described in
Section~\ref{sec:eval}. Contestants are invited to raise questions
through GitHub issues should there be any unclear points in the
description.

\section{Case description}
\label{sec:case}

The present case study requires contestants to use their favorite
technology to write an execution engine for a dataflow-oriented
model-to-model transformation language. The transformation language
has been designed with a simplistic syntax and a limited set of
primitives, in order to be feasible for the time available during TTC.

The first part of the description is dedicated to introducing the
language. Section~\ref{sec:asyn} presents the abstract syntax of the
language and describes the intended semantics for its various
primitives. Section~\ref{sec:csyn} explains the concrete syntaxes
defined, with a HUTN-like simple textual notation and a
boxes-and-arrows graphical notation. Section~\ref{sec:f2p} gives a
walkthrough of a simple transformation written in the language.

After this, two tasks are defined: one is to support the most basic
primitives so the simple example shown in Section~\ref{sec:f2p} can
run. The other task is to support the rest of the primitives and
enable a more complex transformation to be run.

\subsection{Abstract syntax}
\label{sec:asyn}

The abstract syntax of the language has been implemented as an Ecore
metamodel, which is available on the Github repository. Broadly
speaking, it is based on a graph of primitives (shown in
Figure~\ref{fig:ast-primitives}) which may contain expression trees
(Figure~\ref{fig:ast-expressions}).

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{../dsl/eu.ttc.dataflow.model/model/primitives}
  \caption{Abstract syntax: primitives}
  \label{fig:ast-primitives}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{../dsl/eu.ttc.dataflow.model/model/expressions}  
  \caption{Abstract syntax: expressions}
  \label{fig:ast-expressions}
\end{figure}

\subsubsection{Primitives}

As shown in Figure~\ref{fig:ast-primitives}, a transformation is
defined as a \class{Model} that contains a collection of connected
\class{Element}s. These generally take a sequence of ``rows'' (a
collection of key/value pairings) and process them in some way,
forwarding the resulting tuples to the \emph{target}
\class{Element}. Some elements have more than one possible target in
order to allow for more advanced behaviour (e.g. \class{Filter} can
split tuples into two streams according to a condition).

% AGD: hide primitives which don't need to be implemented?

The primitives can be divided into several groups. First, there are
the object handling primitives:

\begin{itemize}
\item \class{AllInstances}: for each input row $r$, it produces one
  new row $r'$ for each instance of the specified type within the
  specified package and model, where the specified field will be set
  to that instance. Package and model are optional.

  If this step has no incoming edges, it will act as it received a
  single empty row, producing one row per instance of the specified
  type from scratch. It will be very commonly the first step in most
  transformations.

\item \class{NewInstance}: evaluates the \emph{key} expression against
  each input tuple and tests if an instance of the same type was
  previously created against the same key (potentially from another
  \class{NewInstance} step). If it was not, it will set the field
  mentioned in \emph{instanceField} to a new instance of the specified
  type and package within the specified model. Otherwise, it will set
  the same field to the previously created element.

  The usage of a key is meant to provide a similar facility to the
  \emph{equivalent()} operation in popular languages such as ATL or
  ETL.

\item \class{GetFeature}: reads a feature (e.g. an attribute or
  reference) from an object in a field of the input row and places it
  as a field of the output row. Useful in combination with
  \class{AddToContainer} later.

\item \class{SetFeature}: sets a feature of an object to the result of
  a certain \class{Expression} on each input row.
\end{itemize}

There are primitives for computing derived values and operating on
collections:

\begin{itemize}
\item \class{Evaluate}: computes an arbitrary expression on the
  current input row and places it as a field on the output row.

\item \class{NewContainer}: creates a new, empty container as a field
  on each input row. The container may be a set, or a list.

\item \class{AddToContainer}: adds an element (potentially at a
  certain position) to the container present in a certain field of the
  input row. This operation has been treated as a primitive, as it may
  need specific considerations for incremental processing.
\end{itemize}

More primitives are available for managing rows:

\begin{itemize}
\item \class{Filter}: for each input row, evaluates the
  \emph{filterBy} expression. Rows that produce a \emph{true} value
  are sent through the \emph{target} element, and those that produce a
  \emph{false} value are sent through the \emph{rejectTarget} element.

\item \class{Copy}: duplicates the same input rows in the same order
  to the \emph{target} and \emph{copyTarget} elements.

\item \class{Product}: this step is intended to receive rows from two
  \class{Element}s and generate the cartesian product of the two sets
  of rows (e.g. produce all pairs of rows from both elements).

\item \class{Sort}: reads in all the rows and then sorts them
  according to the values produced by the \emph{sortBy} expression.

\item \class{ForEach}: for each input row with a collection on a
  certain field, it produces as many rows as elements in that
  collection, setting a certain field to each of its elements.

\item \class{CollectBy}: for each sequence of contiguous rows with the
  same value for \emph{collectBy}, it will produce one row replacing
  all fields with collections of their respective values in the
  sequence.
\end{itemize}

While these are quite a few primitives, not all of them need to be
implemented to run the transformations proposed in this case
study. The required primitives will be mentioned later on.

\subsubsection{Expressions}

As mentioned above, some of these \class{Element}s can embed
\class{Expression}s in order to compute derived values,
sorting/grouping keys or filtering
conditions. Figure~\ref{fig:ast-expressions} shows the available
elements for the small expression language. The objective of the
language is to be side-effect free as much as possible. An expression
is a tree of elements of various types:

\begin{itemize}
\item Literals of a certain type, e.g. \class{BooleanLiteral} for
  boolean values and so forth.

\item \class{FieldReference}s to a certain field within the row, by
  name.

\item \class{UnaryOperation}s, which take the result of a
  subexpression and apply to it logical negation (\emph{NOT} in
  \class{UnaryOperator}) or arithmetic negation (\emph{NEGATION}).

\item \class{BinaryOperation}s, which combine the result of two
  subexpressions in various ways. The language supports equality
  comparison (\emph{EQ} in \class{BinaryOperator}), inequality
  (\emph{NE}), greater than (\emph{GT}), greater or equal (\emph{GE}),
  less than (\emph{LT}), less or equal (\emph{LE}), logical AND with
  shortcircuit, logical OR with shortcircuit, logical XOR, numeric
  addition / string concatenation (\emph{ADD}), subtraction,
  multiplication, division or the modulo operation.

\item \class{FeatureCall}s, which access a certain property or method
  within an object contained in the present row. If it is a method
  call, it will include a list of parameter subexpressions. The
  transformations to be run assume that ``a.x'' will be translated to
  ``a.eGet(feature x)'' in EMF terms, and that ``a.eClass'' and
  ``a.eContainer'' will also be available.

\item \class{ConditionalExpression}s, inspired by the ternary operator
  in C/C++ and by the \emph{if..then..else} expression in Python. If
  the conditional expression produces a \emph{true} value it will
  compute and return the result of the \emph{thenExpression},
  otherwise it will use the \emph{elseExpression}.
\end{itemize}

\subsection{Concrete syntax}
\label{sec:csyn}

Explain the textual (Xtext-based) and graphical (Sirius-based)
notations. Doesn't need to be too detailed, as contestants won't
actually write transformations.

\subsection{Example: Families to Persons}
\label{sec:f2p}

Explain the Families2Persons example as described through the
notations.

\subsection{Task 1: base primitives}
\label{sec:baseprim}

% tree2graph: AllInstances, Evaluate, Filter, NewInstance, SetFeature
% families2persons: AllInstances, Evaluate, Filter, NewInstance, SetFeature

families2persons could be implemented, then tree2graph could be the
``extra'' transformation for soundness.

\subsection{Task 2: extended primitives}
\label{sec:extprim}

% flowchart2html: base + ForEach, AddToContainer
% flowchart2html-alt: flowchart2html + conditional expressions
% class2rdb: base + AddToContainer

flowchart2html could be implemented, then class2rdb could be the
``shadow'' transformation for soundness.

\section{Evaluation}
\label{sec:eval}

Correctness (w/shadow transformation with base primitives revealed
during conference), performance, extensibility.

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
